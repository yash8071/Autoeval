{
  "assignment": 3,
  "assignment_files": {
    "src-tokenizer/tokenizer.pkl": [
      "src[_.-]tokenizer",
      "tokenizer(?:.*)?\\.pkl"
    ],
    "tgt-tokenizer/tokenizer.pkl": [
      "tgt[_.-]tokenizer",
      "tokenizer(?:.*)?\\.pkl"
    ],
    "rnn.enc-dec/loss.json": [
      "rnn[_.-]enc[_.-]dec",
      "loss(?:.*)?\\.json"
    ],
    "rnn.enc-dec/metadata.json": [
      "rnn[_.-]enc[_.-]dec",
      "metadata(?:.*)?\\.json"
    ],
    "rnn.enc-dec/model.pt": [
      "rnn[_.-]enc[_.-]dec",
      "model(?:.*)?\\.pt"
    ],
    "rnn.enc-dec/outputs.csv": [
      "rnn[_.-]enc[_.-]dec",
      "outputs(?:.*)?\\.csv"
    ],
    "rnn.enc-dec.attn/loss.json": [
      "rnn[_.-]enc[_.-]dec[_.-]attn",
      "loss(?:.*)?\\.json"
    ],
    "rnn.enc-dec.attn/metadata.json": [
      "rnn[_.-]enc[_.-]dec[_.-]attn",
      "metadata(?:.*)?\\.json"
    ],
    "rnn.enc-dec.attn/model.pt": [
      "rnn[_.-]enc[_.-]dec[_.-]attn",
      "model(?:.*)?\\.pt"
    ],
    "rnn.enc-dec.attn/outputs.csv": [
      "rnn[_.-]enc[_.-]dec[_.-]attn",
      "outputs(?:.*)?\\.csv"
    ],
    "assignment3.py": "[\\w\\s]+(?:[-_](?:\\d{5}))?(?:[-_]assignm(?:en?|ne)t[_-]?3)?(?:.*)\\.py"
  },
  "assignment_code_file": "assignment3.py",
  "assignment_variables": {
    "STUDENT_SAP_NAME": "str",
    "STUDENT_SR_NUMBER": "str",
    "SRC_VOCAB_SIZE": "int",
    "TGT_VOCAB_SIZE": "int",
    "rnn_enc_dec_params": "dict",
    "rnn_enc_dec_data_params": "dict",
    "rnn_enc_dec_training_params": "dict",
    "rnn_enc_dec_attn_params": "dict",
    "rnn_enc_dec_attn_data_params": "dict",
    "rnn_enc_dec_attn_training_params": "dict",
    "optimizer": "code",
    "criterion": "code",
    "ATTEMPTED_BONUS": "bool"
  }
}